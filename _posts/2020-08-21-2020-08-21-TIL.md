---
layout: post
title: "[2020-08-21] Python Job Scrapper"
date: 2020-08-21
excerpt: "2020-08-21 (금) Python Job Scrapper"
category: [TIL]
tags: [til]
comments: false
---


### Contents
{:.no_toc}
---

* 
{:toc}


# Python

---

## Job Scrapper

---

- indeed.com 페이지 스크랩
- beautiful soup4와 requests(urllib 보다 업그레이드) 패키지 사용
- 더 많은 항목을 볼 수 있도록  맞춤검색에서 항목수를 50으로 조정 (URL에서 limit=50)
- live coding을 할 수 있는 [repl.it](http://repl.it)에서 코딩
- repl.it의 pakages에 들어가서 beautifulsoup4와 requests를 추가한다.

### main.py

```python
import requests
from bs4 import BeautifulSoup

indeed_result = requests.get("https://kr.indeed.com/%EC%B7%A8%EC%97%85?as_and=python&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&radius=25&l=%EC%84%9C%EC%9A%B8&fromage=any&limit=50&sort=&psf=advsrch&from=advancedsearch")
# limit=50

indeed_soup = BeautifulSoup(indeed_result.text, "html.parser")

pagination = indeed_soup.find("div", {"class":"pagination"})

links = pagination.find_all('a')

pages = []

for link in links:
	pages.append(link.find("span"))
print(pages[:-1])
```

`requests` 패키지 import, `BeautifulSoup` 패키지를 `bs4`라는 alias로 import

`requests.get()`으로 URL에서 받아온 요청을 `indeed_result` 인스턴스에 저장

text로 변환된 `indeed_result`를 `html.parser`로 지정해 `indeed_soup`에 저장

`indeed_soup`로 받아온 변환된 text내용(html) 중 div태그 안의 class가 'pagination'인 내용을 찾아 `pagination`에 저장한다.

`pagination`의 텍스트 내용 중 a태그에 해당하는 것을 find_all해서 links라는 변수에 저장

`pages`라는 배열을 선언하고 for문을 사용해 `links`라는 배열에 find_all해서 들어간 내용들을 하나하나 link에 담고 link에 담긴 내용을 `find()`로 span태그를 찾아 `pages`라는 배열에 차례대로 append한다.

pages 배열에 담긴 내용 중에서 제일 뒤에서 마지막 부분을 빼고 전부 출력한다.

![next](https://user-images.githubusercontent.com/40714505/90993532-2c844880-e5f0-11ea-8e6f-f0459bdcd21a.png)

- pages 배열에 담긴 페이지 Number에 해당하는 내용들을 출력한다.

### 실행결과
{:.no_toc}
```
[<span class="pn">2</span>, <span class="pn">3</span>, <span class="pn">4</span>, <span class="pn">5</span>, <span class="pn">6</span>, <span class="pn">7</span>, <span class="pn">8</span>, <span class="pn">9</span>, <span class="pn">10</span>, <span class="pn">11</span>, <span class="pn">12</span>, <span class="pn">13</span>, <span class="pn">14</span>, <span class="pn">15</span>]
```

### String Method 사용

link 안의 span태그에서 anchor가 아닌 string을 찾아오기 위해서는 `link.find("span").string` 으로 string을 찾아온다. 하지만 이를 사용하지 않고 아래와 같은 코드로 생략하고 바로 string method를 사용해줘도 되는데 이는 내용이 anchor와 string으로 구분되어 있기 때문이다.

- string method는 anchor(<>)를 무시하고 string에 해당하는 내용만 가져온다.

```python
...

for link in links:
	pages.append(link.string)
pages = pages[:-1]
print(pages)
```

### 실행결과
{:.no_toc}
```
['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15']
```

### link.string을 int로 형변환하고 가장 큰 숫자 찾기

위의 방식을 사용하면 `links` 내부에 초기에 무시해줬던 마지막 내용(Next 링크)이 들어가기 때문에 int로 casting 할 시에 에러가 발생한다.

- 이를 막기 위해서 for문에서 받아올 때부터 `links[:-1]`을 이용해서 마지막 내용을 제외해준다.
- 최대 페이지 수만큼 request를 보내기 위해서 `pages` 배열에서 마지막 부분(가장 큰 숫자)를 `max_page`에 대입한다.

```python
...

for link in links[:-1]:
	pages.append(int(link.string))
max_page = pages[-1] # 가장 큰 숫자를 찾아서 대입
```

### 실행결과
{:.no_toc}
```
15
```

### Page의 start값

2페이지의 start값은 50으로 3페이지는 100이런식으로 50씩 증가하는 것으로 알 수 있다. 첫 페이지의 start값은 0인 것으로 유추 가능하다.

- index값에 50씩을 곱해서 start를 구하면 된다.

max_page의 start값은 14 * 50으로 700으로 계산된다.

![start700](https://user-images.githubusercontent.com/40714505/90993536-2e4e0c00-e5f0-11ea-891f-3aa1f813116c.png)

실제로 개발자 도구에서 15페이지의 start값은 700인 것을 알 수 있다.

```python
...

max_page = pages[-1]

for n in range(max_page):
	print(f"start={n*50}")
```

range를 이용해 받아온 index값(n)에 50씩 곱하고 start=형식으로 묶어줘서 print 해줬다.

### 실행결과
{:.no_toc}
```
start=0
start=50
start=100
start=150
start=200
start=250
start=300
start=350
start=400
start=450
start=500
start=550
start=600
start=650
start=700
```

### indeed.py

```python
import requests
from bs4 import BeautifulSoup

INDEED_URL = "https://kr.indeed.com/%EC%B7%A8%EC%97%85?as_and=python&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&radius=25&l=%EC%84%9C%EC%9A%B8&fromage=any&limit=50&sort=&psf=advsrch&from=advancedsearch"

def extract_indeed_pages():
	result = requests.get(INDEED_URL)

	soup = BeautifulSoup(result.text, "html.parser")

	pagination = soup.find("div", {"class":"pagination"})

	links = pagination.find_all('a')

	pages = []

	for link in links[:-1]:
		pages.append(int(link.string))

	max_page = pages[-1]

	return max_page
```

indeed.py를 만들어 main의 내용을 옮겨주고 함수로 만들어 재사용할 수 있도록 `extract_indeed_pages()`를 만들어 주고 하드코딩을 방지하기 위해 definition으로 `INDEED_URL`을 지정한다.

### main.py

```python
from indeed import extract_indeed_pages

max_indeed_pages = extract_indeed_pages()

print(max_indeed_pages)
```

indeed에서 사용할 함수인 `extract_indeed_pages`만 import해주고 해당 함수를 `max_indeed_pages`에 담고 print한다. (`max_page`가 리턴된다.)

### 실행결과
{:.no_toc}
```
15
```
### indeed.py

```python
LIMIT = 50

URL = "https://kr.indeed.com/%EC%B7%A8%EC%97%85?q=python&l=%EC%84%9C%EC%9A%B8&limit={LIMIT}"

def extract_indeed_pages():
	result = requests.get(URL)

	soup = BeautifulSoup(result.text, "html.parser")

	pagination = soup.find("div", {"class":"pagination"})

	links = pagination.find_all('a')

	pages = []

	for link in links[:-1]:
		pages.append(int(link.string))
	max_page = pages[-1]
	return max_page

def extract_indeed_jobs(last_page):
	for page in range(last_page):
		result = requests.get(f"{URL}&start={page*LIMIT}")
		print(result.status_code)
```

### main.py

```python
from indeed import extract_indeed_pages, extract_indeed_jobs

last_indeed_page = extract_indeed_pages()

extract_indeed_jobs(last_indeed_page)
```

### indeed.py

- 실제 강좌의 웹사이트와 내가 실습하는 사이트는 구조가 조금 달라서 조금 변형을 해야 한다. (한국사이트와 외국사이트의 차이)

```python
import requests
from bs4 import BeautifulSoup

LIMIT = 50

URL = "https://kr.indeed.com/%EC%B7%A8%EC%97%85?q=python&l=%EC%84%9C%EC%9A%B8&limit={LIMIT}"

def extract_indeed_pages():
	result = requests.get(URL)

	soup = BeautifulSoup(result.text, "html.parser")

	pagination = soup.find("div", {"class":"pagination"})

	links = pagination.find_all('a')

	pages = []

	for link in links[:-1]:
		pages.append(int(link.string))
	max_page = pages[-1]
	return max_page

def extract_indeed_jobs(last_page):
	jobs = []
	# for page in range(last_page):
	result = requests.get(f"{URL}&start={0*LIMIT}")
	soup = BeautifulSoup(result.text, "html.parser")
	results = soup.find_all("div", {"class": "jobsearch-SerpJobCard"})
	for result in results:
		title = result.find("h2", {"class": "title"}).find("a")["title"]
		print(title)
	return jobs
```

![_](https://user-images.githubusercontent.com/40714505/90993542-3c9c2800-e5f0-11ea-923c-6000260ca87c.png)

### 실행결과
{:.no_toc}
```
Data Analytics Specialist
Junior Full-stack Developer
현대오토에버 경력사원 대규모 상시
BS Marketing Anlaytics 인원
[Clova] Clova AI 인재
Customer Engagement Specialist
SW engineer intern
빅데이터/AI 분석
[전문연구요원] 상시
Developer / Designer recruit
다나와 - 2020년 신입/경력직
Cross Border Ecommerce - Business Intelligence (Based in Seoul)
[Clova] Cross Platform Python Packaging Intern
AI/빅데이터/클라우드 분야 (인재 Pool)
[피파온라인4] 테크니컬 아티스트
```
### def extract_indeed_jobs

```python
def extract_indeed_jobs(last_page):
	jobs = []
	# for page in range(last_page):
	result = requests.get(f"{URL}&start={0*LIMIT}")
	soup = BeautifulSoup(result.text, "html.parser")
	results = soup.find_all("div", {"class": "jobsearch-SerpJobCard"})
	for result in results:
		title = result.find("h2", {"class": "title"}).find("a")["title"]
		company = result.find("span", {"class": "company"})
		company_anchor = company.find("a")
		if company_anchor is not None:
			company = company_anchor.string
		else:
			company = company.string
		company = company.strip()
		print(title, ":",company)
	return jobs
```

company_anchor가  None이 나오는 경우는 태그에 회사 링크가 없는 경우이기 때문에 None이 나오면 string만 출력하도록하고 링크가 있으면 a태그 안에서 회사명을 string으로 뽑아오도록한다.

### 실행결과
{:.no_toc}
```
Junior Full-stack Developer : Asiance
Data Analytics Specialist : Philip Morris International
[Clova] Clova AI 인재 : 네이버
SW engineer intern : Intel
빅데이터/AI 분석 : 현대자동차그룹
Customer Engagement Specialist : Sanofi
다나와 - 2020년 신입/경력직 : 다나와
[전문연구요원] 상시 : 네이버
Cross Border Ecommerce - Business Intelligence (Based in Seoul) : Shopee
Developer / Designer recruit : 마이뮤직테이스트
[Clova] Cross Platform Python Packaging Intern : 네이버
BS Marketing Anlaytics 인원 : LG전자
현대오토에버 경력사원 대규모 상시 : 현대오토에버
AI/빅데이터/클라우드 분야 (인재 Pool) : LG유플러스
[피파온라인4] 테크니컬 아티스트 : Electronic Arts
```
이번에는 location 정보를 포함해서 출력한다.

![tempsnip](https://user-images.githubusercontent.com/40714505/90993544-3efe8200-e5f0-11ea-840b-6b33238a501e.png)


### main.py

```python
from indeed import extract_indeed_pages, extract_indeed_jobs

last_indeed_page = extract_indeed_pages()

indeed_jobs = extract_indeed_jobs(last_indeed_page)

print(indeed_jobs)
```

### indeed.py

```python
import requests
from bs4 import BeautifulSoup

LIMIT = 50

URL = "https://kr.indeed.com/%EC%B7%A8%EC%97%85?q=python&l=%EC%84%9C%EC%9A%B8&limit={LIMIT}"

def extract_indeed_pages():
    result = requests.get(URL)

    soup = BeautifulSoup(result.text, "html.parser")

    pagination = soup.find("div", {"class": "pagination"})

    links = pagination.find_all('a')

    pages = []

    for link in links[:-1]:
        pages.append(int(link.string))
    max_page = pages[-1]
    return max_page

def extarct_job(html):
    title = html.find("h2", {"class": "title"}).find("a")["title"]
    company = html.find("span", {"class": "company"})
    company_anchor = company.find("a")
    if company_anchor is not None:
        company = company_anchor.string
    else:
        company = company.string
    company = company.strip()
    location = html.find("span", {"class": "location"}).string
    job_id = html["data-jk"]

    return {
        'title': title,
        'company': company,
        'location': location,
        'link': f'https://kr.indeed.com/viewjob?jk={job_id}'
    }

def extract_indeed_jobs(last_page):
    jobs = []
    for page in range(last_page):
        print(f"Scrapping page {page}")
        result = requests.get(f"{URL}&start={page*LIMIT}")
        soup = BeautifulSoup(result.text, "html.parser")
        results = soup.find_all("div", {"class": "jobsearch-SerpJobCard"})
        for result in results:
            job = extarct_job(result)
            jobs.append(job)
    return jobs
```

### 실행결과
{:.no_toc}
```
Scrapping page 0
Scrapping page 1
Scrapping page 2
Scrapping page 3
Scrapping page 4
[
{'title': 'SW engineer intern', 'company': 'Intel', 'location': '서울', 'link': 'https://kr.indeed.com/viewjob?jk=ae042b7756b8eecd'},
{'title': 'Junior Full-stack Developer', 'company': 'Asiance', 'location': '서울', 'link': 'https://kr.indeed.com/viewjob?jk=fb84164a9eed9423'},
{'title': 'Data Analytics Specialist', 'company': 'Philip MorrisInternational', 'location': '서울', 'link': 'https://kr.indeed.comviewjob?jk=05e5e5314b49e28f'},
{'title': '[Clova] Clova AI 인재', 'company': '네이버', 'location':'서울', 'link': 'https://kr.indeed.com/viewjob?jk=92bd400e3b5306ba'},
{'title': 'BS Marketing Anlaytics 인원', 'company': 'LG전자','location': '서울 영등포구', 'link': 'https://kr.indeed.com/viewjobjk=d826f74b1952b4b7'},
{'title': '빅데이터/AI 분석', 'company': '현대자동차그룹', 'location':'서울', 'link': 'https://kr.indeed.com/viewjob?jk=8693f8e419a62c05'},
{'title': 'Customer Engagement Specialist', 'company': 'Sanofi','location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=bb76e00964d6cec6'},
{'title': '[전문연구요원] 상시', 'company': '네이버', 'location':'서울', 'link': 'https://kr.indeed.com/viewjob?jk=b79c2ae536063b01'},
{'title': '다나와 - 2020년 신입/경력직', 'company': '다나와','location': '서울 양천구', 'link': 'https://kr.indeed.com/viewjobjk=4bbf089061516876'},
{'title': '[Clova] Cross Platform Python Packaging Intern', 'company':'네이버', 'location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=85d495b911ccfb21'}, 
{'title': 'Developer / Designer recruit', 'company':'마이뮤직테이스트', 'location': '서울 논현동', 'link': 'https://krindeed.com/viewjob?jk=55a19c92c845685e'}, 
{'title': 'Cross Border Ecommerce - Business Intelligence (Based inSeoul)', 'company': 'Shopee', 'location': '서울', 'link': 'https://krindeed.com/viewjob?jk=b574f1454ae36aab'}, 
{'title': '현대오토에버 경력사원 대규모 상시', 'company': '현대오토에버','location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=ba9770b7b17a038e'}, 
{'title': 'AI/빅데이터/클라우드 분야 (인재 Pool)', 'company':'LG유플러스', 'location': '서울', 'link': 'https://kr.indeed.comviewjob?jk=fb617eeb80ea6fa9'}, 
{'title': '[피파온라인4] 테크니컬 아티스트', 'company': 'ElectronicArts', 'location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=0bce5c7e8c1e521d'}, 
{'title': 'Machine Learning 엔지니어 영입', 'company': '카카오모빌리티','location': '성남 분당구', 'link': 'https://kr.indeed.com/viewjobjk=bee9e8796eb54164'}, 
{'title': '[인재풀] 아티스트', 'company': 'Electronic Arts','location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=aac8e9355cb855ac'}, 
{'title': '[AI R&D] Language AI(NLP) Research 분야 수시 채용','company': '엔씨소프트', 'location': '성남 판교역', 'link': 'https://krindeed.com/viewjob?jk=f4190a8dbb8c05b1'}, 
{'title': '[NAVERxLINE] Global Ad AI Engineer/AI Planner', 'company':'네이버', 'location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=a358a39da5dfc360'}, 
{'title': 'Internal Infra Engineer', 'company': 'Toss', 'location':'서울 강남구', 'link': 'https://kr.indeed.com/viewjobjk=741cc6ac364ea9be'}, 
{'title': 'Launcher팀 소프트웨어 엔지니어', 'company': 'Nexon','location': '성남 분당구', 'link': 'https://kr.indeed.com/viewjobjk=d71794dc69947981'}, 
{'title': 'AI/ 음성인식/ 차량보안/ 빅데이터/ IoT 등 R&D 부문 경력','company': '현대오토에버', 'location': '서울 강남구', 'link': 'https:/kr.indeed.com/viewjob?jk=483b5c30ed9ccb06'}, 
{'title': 'Solutions Engineer', 'company': 'Confluent', 'location':'서울', 'link': 'https://kr.indeed.com/viewjob?jk=6a399a2c059ebbb1'}, 
{'title': 'Senior Staff Engineer, FAE Samsung', 'company': 'ams','location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=f8fcba2c93fcc52a'}, 
{'title': 'Back-end Engineer (Python)', 'company': 'Soomgo','location': '서울 강남구', 'link': 'https://kr.indeed.com/viewjobjk=752a4b5d63eac97c'}, 
{'title': '유저프로파일팀 - 데이터 모델러', 'company': 'Nexon','location': '성남 분당구', 'link': 'https://kr.indeed.com/viewjobjk=8dfc9993e2aa9160'}, 
{'title': '데스크탑 가상화(VDI) 엔지니어', 'company': '카카오','location': '성남 판교역', 'link': 'https://kr.indeed.com/viewjobjk=530a598184580c95'}, 
{'title': '데이터 분석 직군 모집', 'company': '넷마블', 'location': '서울구로구', 'link': 'https://kr.indeed.com/viewjob?jk=1c4f1c0b625f5abd'}, 
{'title': 'Cloud Support Engineer II (Network)', 'company': 'AmazonWeb Services Korea LLC', 'location': '서울', 'link': 'https://krindeed.com/viewjob?jk=cfdd56fef2ec9c47'}, 
{'title': 'MongoDB Engineer', 'company': '카카오', 'location': '성남판교역', 'link': 'https://kr.indeed.com/viewjob?jk=2695294aea6dc3b6'}, 
{'title': '(병역특례 보충역 00명 ) 모니터링 / 운영 툴 개발', 'company':'아이앤아이소프트', 'location': '성남 분당구', 'link': 'https://krindeed.com/viewjob?jk=5e6e506c2395c21b'}, 
{'title': 'NAVER, LINE 서비스 플랫폼 운영', 'company': 'NIT Service','location': '성남 삼평동', 'link': 'https://kr.indeed.com/viewjobjk=285996f91e76a862'}, 
{'title': '[AI검색플랫폼] 머신러닝 개발자', 'company':'카카오엔터프라이즈', 'location': '성남 분당구', 'link': 'https://krindeed.com/viewjob?jk=dea246efe3aa55a7'}, 
{'title': '추천 시스템 연구/개발', 'company': '카카오', 'location': '성남판교역', 'link': 'https://kr.indeed.com/viewjob?jk=be6c1f03fa566f8e'}, 
{'title': 'Senior Data Scientist - AWS Professional Services','company': 'Amazon Web Services Korea LLC', 'location': '서울','link': 'https://kr.indeed.com/viewjob?jk=37da5b148b2d3ef4'}, 
{'title': 'Analytics Specialist', 'company': 'MightyHive', 'location':'서울', 'link': 'https://kr.indeed.com/viewjob?jk=419692b3ddb34768'}, 
{'title': '[Search] NAVER Search 이미지 검색서버개발 신입/경력사원','company': '네이버', 'location': '서울', 'link': 'https://kr.indeed.comviewjob?jk=a771637c0eeffc26'}, 
{'title': '사내 시스템 (O365) 구축/관리 엔지니어', 'company': 'Nexon','location': '성남 분당구', 'link': 'https://kr.indeed.com/viewjobjk=b4bd6d5bad3b761c'}, 
{'title': '추천 시스템 소프트웨어 엔지니어', 'company': '카카오','location': '성남 판교역', 'link': 'https://kr.indeed.com/viewjobjk=07375dc4e800dfa9'}, 
{'title': '[Search] [Vision] Computer Vision Engineer 체험형 인턴','company': '네이버', 'location': '서울', 'link': 'https://kr.indeed.comviewjob?jk=a41d35173ffe4666'}, 
{'title': '[기술플랫폼실] 데이터 사이언티스트(Data Scientist) 분석가영입', 'company': '카카오페이', 'location': '성남 분당구', 'link':'https://kr.indeed.com/viewjob?jk=3a3c48cd3026f062'}, 
{'title': '[조직문화/개발팀] 백엔드 엔지니어(전문연구요원 가능)','company': '버즈니', 'location': '서울', 'link': 'https://kr.indeed.comviewjob?jk=a312aadd51cba768'}, 
{'title': 'Data Scientist III', 'company': 'Amazon Web Services KoreaLLC', 'location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=67ca30c143379281'}, 
{'title': '자연어처리 기술 개발자', 'company': 'NHN', 'location': '성남판교역', 'link': 'https://kr.indeed.com/viewjob?jk=9cf16f530cb5e00c'}, 
{'title': 'Web 개발(이커머스 파트)_PHP/CodeIgniter/Javascript','company': '버드뷰', 'location': '서울 마포구', 'link': 'https://krindeed.com/viewjob?jk=3292e81e43884c67'}, 
{'title': '[서울/수원/천안]IT관련분야 훈련생', 'company': '휴먼교육센터','location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=3b5381e88dd3d7e3'},
{'title': '경험최적화파트 - 머신러닝 엔지니어', 'company': 'Nexon','location': '성남 분당구', 'link': 'https://kr.indeed.com/viewjobjk=7bf179a290a157b2'}, 
{'title': '[조인어스코리아]웹 백엔드 개발자', 'company': '조인어스코리아','location': '서울 영등포구', 'link': 'https://kr.indeed.com/viewjobjk=7e0759198648a693'}, 
{'title': '모빌리티 기업 렌카, 데이터 분석 담당자', 'company': '렌카','location': '서울 광진구', 'link': 'https://kr.indeed.com/viewjobjk=4aee3e7a50dce9d2'}, 
{'title': '[경력] 지도 구축 솔루션 개발', 'company': '현대엠엔소프트','location': '서울 용산구', 'link': 'https://kr.indeed.com/viewjobjk=3fa3834bb999829b'}, 
{'title': '[TmaxAI/기술] 기술지원 엔지니어', 'company': '티맥스소프트','location': '성남 분당구', 'link': 'https://kr.indeed.com/viewjobjk=2a8e6fae00c17acc'}, 
{'title': 'O2O Platform Frontend Web(신입/경력)', 'company':'에이치에너지', 'location': '서울 강남구', 'link': 'https://kr.indeedcom/viewjob?jk=f77e874155d137ee'}, 
{'title': '[경력] 데이터 아키텍트(DA)', 'company': '현대엠엔소프트','location': '서울 용산구', 'link': 'https://kr.indeed.com/viewjobjk=312454e44592db50'}, 
{'title': 'Performance Marketer (SA 중심)', 'company': 'Soomgo','location': '서울 강남구', 'link': 'https://kr.indeed.com/viewjobjk=08ac4426aa2a7bed'}, 
{'title': '위시켓과 함께할 서버개발자님', 'company': '위시켓','location': '서울 강남구', 'link': 'https://kr.indeed.com/viewjobjk=a3a65a4d59061430'}, 
{'title': '데이터 엔지니어', 'company': '크로스앵글', 'location': '서울반포동', 'link': 'https://kr.indeed.com/viewjob?jk=ae15250b0a7f47e0'},
{'title': '[Search] [Vision] Computer Vision Engineer 신입/경력사원','company': '네이버', 'location': '서울', 'link': 'https://kr.indeed.comviewjob?jk=fe383fbe18dc32e1'}, 
{'title': '모바일 앱 보안 솔루션 개발부문', 'company': '스틸리언','location': '서울 용산구', 'link': 'https://kr.indeed.com/viewjobjk=6718bba08ef6e20b'}, 
{'title': '(주)이랜서 웹 개발자 인재 초대 (정규직/본사근무)', 'company':'이랜서', 'location': '서울 강남구', 'link': 'https://kr.indeed.comviewjob?jk=2c282ae7cf933e8c'}, 
{'title': 'Senior Data Scientist - AWS Professional Services Korea','company': 'Amazon Web Services Korea LLC', 'location': '서울','link': 'https://kr.indeed.com/viewjob?jk=d8dbed4efb6aa668'}, 
{'title': 'Credit Risk Manager', 'company': 'Toss', 'location': '서울강남구', 'link': 'https://kr.indeed.com/viewjob?jk=3929f9c03665e38e'}, 
{'title': '[XR Experience] 메디컬 콘텐츠 Unity 개발 경력자', 'company':'테트라시그넘', 'location': '서울 송파구', 'link': 'https://kr.indeedcom/viewjob?jk=993c3077a05b9867'}, 
{'title': '[Search] 글로벌 검색 서비스 개발', 'company': '네이버','location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=bd77137b5b82c7e0'}, 
{'title': 'Data Engineer', 'company': '레이니스트', 'location': '서울','link': 'https://kr.indeed.com/viewjob?jk=02dd3cb5f0906404'}, 
{'title': '[메가존클라우드] Cloud Infra System engineer', 'company':'메가존', 'location': '서울 강남구', 'link': 'https://kr.indeed.comviewjob?jk=b60dc669f610898d'}, 
{'title': '[Search] 데이터 플랫폼 개발 신입/경력사원', 'company':'네이버', 'location': '서울', 'link': 'https://kr.indeed.com/viewjobjk=f9792e063008d201'}, 
{'title': 'Alibaba Cloud Intelligence Solutions Architect SouthKorea', 'company': 'Alibaba', 'location': '서울', 'link': 'https://krindeed.com/viewjob?jk=d8b903e3573250b1'}, 
{'title': '[ESTgames]MMORPG·SNG 개발자 수시', 'company': '이스트게임즈','location': '서울 서초구', 'link': 'https://kr.indeed.com/viewjobjk=07f602c377fed355'}, 
{'title': '백엔드 개발자 (경력)', 'company': '크로스앵글', 'location':'서울 반포동', 'link': 'https://kr.indeed.com/viewjobjk=af5683389907a8c9'}, 
{'title': 'Data Engineer', 'company': 'Toss', 'location': '서울 강남구', 'link': 'https://kr.indeed.com/viewjob?jk=30397f4de3627e9d'}
]
```